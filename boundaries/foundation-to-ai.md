# Boundary: Foundation → AI / Intelligence

## Purpose

Define the boundary between the **ICE Foundation**
and the **ICE AI / Intelligence** domain.

This document establishes what the Foundation constrains
with respect to intelligence, inference, and reasoning,
and what it explicitly does **not** define, perform, or decide.

The goal is to prevent intelligence from acquiring
implicit authority over truth, execution, or governance.

---

## Role of the Foundation

The ICE Foundation:

- Defines axioms that constrain meaning and validity
- Defines structural invariants (authority, traceability, determinism)
- Establishes what intelligence is allowed to affect
- Separates **inference** from **control**

The Foundation does **not** reason.

---

## Role of AI / Intelligence

AI / Intelligence:

- Performs inference, reasoning, and pattern extraction
- Produces intent, hypotheses, and proposals
- Operates under explicit authority constraints
- Never executes actions autonomously

AI answers **what might be done**,
never **what is allowed to happen**.

---

## Explicit Non-Responsibilities of the Foundation

The Foundation does NOT define:

- Model architectures or training strategies
- Inference techniques or algorithms
- Learning mechanisms or adaptation logic
- Prompting, planning, or optimization strategies
- Intelligence performance or accuracy metrics

All such concerns belong exclusively to the AI domain.

---

## Constraint Relationship

- The Foundation constrains **authority and effect**
- AI produces **intent**, not action
- AI output must always be mediated by authority
- No inference result is self-authorizing

If an AI decision bypasses authority or traceability,
the AI system is invalid — not the Foundation.

---

## Invalid Boundary Violations

The following are invalid:

- Treating inference as authority
- Allowing AI to execute or enforce decisions
- Encoding intelligence behavior as axioms
- Using AI output to redefine invariants

Such actions violate the boundary.

---

## Canonical Status

This boundary is authoritative.

Any AI or intelligent subsystem claiming ICE compliance
must demonstrate strict separation between
inference, authority, and execution.

The Foundation constrains AI impact.  
AI never extends Foundation authority.
